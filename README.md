# Adversarial-Attack-CIFAR100-
This project uses Fast Gradient Sign Attack (FGSM) to expose neural network vulnerabilities. Tests on CIFAR-100 show accuracy drops with small perturbations, highlighting security risks. Findings stress the need for stronger defenses in deep learning.
